{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4a46a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8954, 2)\n",
      "Validation shape: (1076, 2)\n",
      "Test shape: (1076, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what alarms do i have set right now</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkout today alarm of meeting</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report alarm settings</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see see for me the alarms that you have set to...</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there an alarm for ten am</td>\n",
       "      <td>alarm_query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     category\n",
       "0                what alarms do i have set right now  alarm_query\n",
       "1                    checkout today alarm of meeting  alarm_query\n",
       "2                              report alarm settings  alarm_query\n",
       "3  see see for me the alarms that you have set to...  alarm_query\n",
       "4                       is there an alarm for ten am  alarm_query"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = r'/home/manh/code/nlp/src/data/hwu'\n",
    "train_path = os.path.join(data_path, 'train.csv')\n",
    "val_path =  os.path.join(data_path, 'val.csv')\n",
    "test_path = os.path.join(data_path, 'test.csv')\n",
    "\n",
    "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Validation shape:\", df_val.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f996f",
   "metadata": {},
   "source": [
    "Encoding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7386996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['label_encoded'] = label_encoder.fit_transform(df_train['category'])\n",
    "df_val['label_encoded'] = label_encoder.transform(df_val['category'])\n",
    "df_test['label_encoded'] = label_encoder.transform(df_test['category'])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860075f",
   "metadata": {},
   "source": [
    "TFIDF + LOGISTIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fc865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        19\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.81      0.89      0.85        19\n",
      "           3       1.00      0.75      0.86         8\n",
      "           4       0.92      0.80      0.86        15\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       0.45      0.53      0.49        19\n",
      "           7       0.89      0.89      0.89        19\n",
      "           8       0.81      0.68      0.74        19\n",
      "           9       0.59      0.68      0.63        19\n",
      "          10       0.67      0.75      0.71         8\n",
      "          11       0.74      0.89      0.81        19\n",
      "          12       0.78      0.88      0.82         8\n",
      "          13       0.83      0.79      0.81        19\n",
      "          14       0.92      0.63      0.75        19\n",
      "          15       0.81      0.89      0.85        19\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       0.90      1.00      0.95        19\n",
      "          20       1.00      0.95      0.97        19\n",
      "          21       1.00      1.00      1.00        12\n",
      "          22       0.95      1.00      0.97        19\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.36      0.26      0.30        19\n",
      "          25       0.90      1.00      0.95        19\n",
      "          26       1.00      1.00      1.00        16\n",
      "          27       1.00      0.95      0.97        19\n",
      "          28       0.75      0.79      0.77        19\n",
      "          29       0.91      0.83      0.87        12\n",
      "          30       0.89      0.89      0.89        19\n",
      "          31       0.67      0.67      0.67         3\n",
      "          32       0.92      0.86      0.89        14\n",
      "          33       0.80      0.89      0.84         9\n",
      "          34       0.78      1.00      0.88         7\n",
      "          35       0.68      0.79      0.73        19\n",
      "          36       0.75      0.79      0.77        19\n",
      "          37       0.85      0.89      0.87        19\n",
      "          38       0.65      0.61      0.63        18\n",
      "          39       0.71      0.53      0.61        19\n",
      "          40       1.00      0.57      0.73         7\n",
      "          41       0.75      0.63      0.69        19\n",
      "          42       0.95      0.95      0.95        19\n",
      "          43       0.81      0.68      0.74        19\n",
      "          44       0.58      0.74      0.65        19\n",
      "          45       1.00      0.84      0.91        19\n",
      "          46       0.89      0.84      0.86        19\n",
      "          47       0.94      0.89      0.92        19\n",
      "          48       0.82      0.95      0.88        19\n",
      "          49       0.48      0.58      0.52        19\n",
      "          50       0.92      0.86      0.89        14\n",
      "          51       1.00      0.95      0.97        19\n",
      "          52       0.83      0.79      0.81        19\n",
      "          53       0.81      0.89      0.85        19\n",
      "          54       1.00      1.00      1.00        10\n",
      "          55       0.95      1.00      0.97        19\n",
      "          56       0.80      0.89      0.84        18\n",
      "          57       0.83      0.79      0.81        19\n",
      "          58       0.89      0.89      0.89        19\n",
      "          59       0.68      0.79      0.73        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.94      0.79      0.86        19\n",
      "          62       1.00      0.95      0.97        19\n",
      "          63       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.84      1076\n",
      "   macro avg       0.84      0.83      0.84      1076\n",
      "weighted avg       0.84      0.84      0.83      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "# 1. Tạo một pipeline với TfidfVectorizer và LogisticRegression\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "# 2. Huấn luyện pipeline trên tập train\n",
    "tfidf_lr_pipeline.fit(df_train['text'], df_train['label_encoded'])\n",
    "\n",
    "# 3. Đánh giá trên tập test\n",
    "y_pred = tfidf_lr_pipeline.predict(df_test['text'])\n",
    "print(classification_report(df_test['label_encoded'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3434950",
   "metadata": {},
   "source": [
    "WORD2VEC (AVG pooling) + DENSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2c8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (44.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/manh/code/nlp/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d023c5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:34:43.539638: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-06 11:34:45.298595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/manh/code/nlp/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-12-06 11:34:49.556922: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-06 11:34:49.560488: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3372 - loss: 2.7840 - val_accuracy: 0.6673 - val_loss: 1.4282\n",
      "Epoch 2/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 1.4746 - val_accuracy: 0.7565 - val_loss: 0.9804\n",
      "Epoch 3/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6647 - loss: 1.1866 - val_accuracy: 0.7714 - val_loss: 0.8481\n",
      "Epoch 4/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 1.0497 - val_accuracy: 0.7900 - val_loss: 0.7819\n",
      "Epoch 5/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.9662 - val_accuracy: 0.7909 - val_loss: 0.7383\n",
      "Epoch 6/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.9061 - val_accuracy: 0.7974 - val_loss: 0.7085\n",
      "Epoch 7/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.8721 - val_accuracy: 0.8076 - val_loss: 0.6853\n",
      "Epoch 8/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7598 - loss: 0.8397 - val_accuracy: 0.8067 - val_loss: 0.6760\n",
      "Epoch 9/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.7927 - val_accuracy: 0.8086 - val_loss: 0.6558\n",
      "Epoch 10/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.7665 - val_accuracy: 0.8197 - val_loss: 0.6523\n",
      "Epoch 11/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.7599 - val_accuracy: 0.8169 - val_loss: 0.6314\n",
      "Epoch 12/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7836 - loss: 0.7397 - val_accuracy: 0.8206 - val_loss: 0.6359\n",
      "Epoch 13/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.7188 - val_accuracy: 0.8281 - val_loss: 0.6180\n",
      "Epoch 14/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.7060 - val_accuracy: 0.8290 - val_loss: 0.6183\n",
      "Epoch 15/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7994 - loss: 0.6927 - val_accuracy: 0.8197 - val_loss: 0.6169\n",
      "Epoch 16/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.6811 - val_accuracy: 0.8206 - val_loss: 0.6081\n",
      "Epoch 17/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.6763 - val_accuracy: 0.8188 - val_loss: 0.6114\n",
      "Epoch 18/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.6549 - val_accuracy: 0.8299 - val_loss: 0.6067\n",
      "Epoch 19/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.6459 - val_accuracy: 0.8299 - val_loss: 0.6009\n",
      "Epoch 20/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.6374 - val_accuracy: 0.8327 - val_loss: 0.6023\n",
      "Epoch 21/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.6316 - val_accuracy: 0.8281 - val_loss: 0.5973\n",
      "Epoch 22/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.6290 - val_accuracy: 0.8309 - val_loss: 0.5899\n",
      "Epoch 23/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.6125 - val_accuracy: 0.8318 - val_loss: 0.5879\n",
      "Epoch 24/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.6045 - val_accuracy: 0.8392 - val_loss: 0.5944\n",
      "Epoch 25/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.6002 - val_accuracy: 0.8262 - val_loss: 0.5932\n",
      "Epoch 26/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.5961 - val_accuracy: 0.8318 - val_loss: 0.5946\n",
      "Epoch 27/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.5822 - val_accuracy: 0.8290 - val_loss: 0.5805\n",
      "Epoch 28/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.5899 - val_accuracy: 0.8299 - val_loss: 0.5770\n",
      "Epoch 29/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.5644 - val_accuracy: 0.8309 - val_loss: 0.5858\n",
      "Epoch 30/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.5578 - val_accuracy: 0.8271 - val_loss: 0.5901\n",
      "Epoch 31/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.5538 - val_accuracy: 0.8299 - val_loss: 0.5892\n",
      "Epoch 32/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.5483 - val_accuracy: 0.8253 - val_loss: 0.5902\n",
      "Epoch 33/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.5409 - val_accuracy: 0.8309 - val_loss: 0.5924\n",
      "Epoch 34/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.5414 - val_accuracy: 0.8401 - val_loss: 0.5840\n",
      "Epoch 35/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.5332 - val_accuracy: 0.8216 - val_loss: 0.5797\n",
      "Epoch 36/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.5292 - val_accuracy: 0.8355 - val_loss: 0.5870\n",
      "Epoch 37/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.5275 - val_accuracy: 0.8309 - val_loss: 0.5913\n",
      "Epoch 38/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.5183 - val_accuracy: 0.8411 - val_loss: 0.5851\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83        19\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       0.68      0.89      0.77        19\n",
      "           3       0.67      0.75      0.71         8\n",
      "           4       0.80      0.80      0.80        15\n",
      "           5       0.77      0.77      0.77        13\n",
      "           6       0.50      0.58      0.54        19\n",
      "           7       1.00      0.89      0.94        19\n",
      "           8       0.71      0.79      0.75        19\n",
      "           9       0.69      0.58      0.63        19\n",
      "          10       0.75      0.75      0.75         8\n",
      "          11       0.73      0.84      0.78        19\n",
      "          12       0.89      1.00      0.94         8\n",
      "          13       0.88      0.74      0.80        19\n",
      "          14       0.76      0.68      0.72        19\n",
      "          15       0.80      0.84      0.82        19\n",
      "          16       0.95      1.00      0.97        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       1.00      1.00      1.00        19\n",
      "          20       1.00      0.74      0.85        19\n",
      "          21       1.00      0.92      0.96        12\n",
      "          22       0.86      1.00      0.93        19\n",
      "          23       0.95      0.95      0.95        19\n",
      "          24       0.46      0.32      0.37        19\n",
      "          25       0.83      1.00      0.90        19\n",
      "          26       0.94      1.00      0.97        16\n",
      "          27       0.83      1.00      0.90        19\n",
      "          28       0.79      0.79      0.79        19\n",
      "          29       0.56      0.83      0.67        12\n",
      "          30       1.00      0.89      0.94        19\n",
      "          31       0.33      0.67      0.44         3\n",
      "          32       0.83      0.36      0.50        14\n",
      "          33       0.78      0.78      0.78         9\n",
      "          34       0.71      0.71      0.71         7\n",
      "          35       0.76      0.84      0.80        19\n",
      "          36       0.81      0.89      0.85        19\n",
      "          37       0.90      0.95      0.92        19\n",
      "          38       0.65      0.72      0.68        18\n",
      "          39       0.73      0.58      0.65        19\n",
      "          40       0.75      0.43      0.55         7\n",
      "          41       0.65      0.68      0.67        19\n",
      "          42       1.00      0.89      0.94        19\n",
      "          43       0.65      0.79      0.71        19\n",
      "          44       0.67      0.74      0.70        19\n",
      "          45       0.85      0.58      0.69        19\n",
      "          46       1.00      0.84      0.91        19\n",
      "          47       1.00      0.95      0.97        19\n",
      "          48       0.89      0.89      0.89        19\n",
      "          49       0.50      0.63      0.56        19\n",
      "          50       0.87      0.93      0.90        14\n",
      "          51       0.95      0.95      0.95        19\n",
      "          52       0.82      0.74      0.78        19\n",
      "          53       0.93      0.68      0.79        19\n",
      "          54       0.91      1.00      0.95        10\n",
      "          55       1.00      0.95      0.97        19\n",
      "          56       0.81      0.94      0.87        18\n",
      "          57       0.76      0.68      0.72        19\n",
      "          58       0.75      0.79      0.77        19\n",
      "          59       0.81      0.68      0.74        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.90      0.95      0.92        19\n",
      "          62       0.86      0.95      0.90        19\n",
      "          63       0.74      0.74      0.74        19\n",
      "\n",
      "    accuracy                           0.82      1076\n",
      "   macro avg       0.81      0.81      0.81      1076\n",
      "weighted avg       0.82      0.82      0.81      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
    "sentences = [text.split() for text in df_train['text']]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, epochs=100)\n",
    "\n",
    "# 2. Viết hàm để chuyển mỗi câu thành vector trung bình\n",
    "def sentence_to_avg_vector(text, model):\n",
    "    # ... (Implement logic)\n",
    "    vectors = [model.wv[word] for word in text.split() if word in model.wv]\n",
    "    avg_vector = np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "    return avg_vector\n",
    "\n",
    "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
    "X_train_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_train['text']])\n",
    "X_val_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_val['text']])\n",
    "X_test_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_test['text']])\n",
    "y_train = df_train['label_encoded'].values\n",
    "y_val = df_val['label_encoded'].values\n",
    "y_test = df_test['label_encoded'].values\n",
    "\n",
    "# 4. Xây dựng mô hình Sequential của Keras\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_avg, y_train,\n",
    "    validation_data=(X_val_avg, y_val),\n",
    "    epochs=100, batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = model.predict(X_test_avg)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a475e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Log Loss on test set: 0.6759335398674011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tính toán loss trên tập test\n",
    "y_pred_proba = model.predict(X_test_avg)\n",
    "log_loss = -np.mean(np.log(y_pred_proba[np.arange(len(y_test)), y_test]))\n",
    "print(f\"Log Loss on test set: {log_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c5feb",
   "metadata": {},
   "source": [
    "# 3 Mô hình EMBEDDING pretrain(word2vec) + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9b5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "\n",
    "vocab_size = len(w2v_model.wv.index_to_key) + 1\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
    "# Padding: Đảm bảo các chuỗi có cùng độ dài\n",
    "max_len = 100\n",
    "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "val_sequences = tokenizer.texts_to_sequences(df_val['text'])\n",
    "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
    "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "#  Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = w2v_model.vector_size\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "lstm_model_pretrained = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
    "        input_length=max_len,\n",
    "        mask_zero=True,\n",
    "        trainable=False # Đóng băng lớp Embedding\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5afd1c",
   "metadata": {},
   "source": [
    "Compile, huấn luyện (sử dụng EarlyStopping) và đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e633b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 127ms/step - accuracy: 0.5553 - loss: 2.0437 - val_accuracy: 0.7593 - val_loss: 0.9384\n",
      "Epoch 2/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 110ms/step - accuracy: 0.7716 - loss: 0.8709 - val_accuracy: 0.8058 - val_loss: 0.6964\n",
      "Epoch 3/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 103ms/step - accuracy: 0.8237 - loss: 0.6701 - val_accuracy: 0.8234 - val_loss: 0.6030\n",
      "Epoch 4/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.8444 - loss: 0.5782 - val_accuracy: 0.8364 - val_loss: 0.5802\n",
      "Epoch 5/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.8576 - loss: 0.5133 - val_accuracy: 0.8467 - val_loss: 0.5496\n",
      "Epoch 6/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.8753 - loss: 0.4527 - val_accuracy: 0.8476 - val_loss: 0.5176\n",
      "Epoch 7/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.8876 - loss: 0.4043 - val_accuracy: 0.8485 - val_loss: 0.5181\n",
      "Epoch 8/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.8950 - loss: 0.3763 - val_accuracy: 0.8448 - val_loss: 0.5341\n",
      "Epoch 9/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9034 - loss: 0.3448 - val_accuracy: 0.8532 - val_loss: 0.5136\n",
      "Epoch 10/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9141 - loss: 0.3112 - val_accuracy: 0.8550 - val_loss: 0.5086\n",
      "Epoch 11/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9198 - loss: 0.2914 - val_accuracy: 0.8513 - val_loss: 0.5203\n",
      "Epoch 12/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 116ms/step - accuracy: 0.9258 - loss: 0.2696 - val_accuracy: 0.8513 - val_loss: 0.5015\n",
      "Epoch 13/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9309 - loss: 0.2472 - val_accuracy: 0.8578 - val_loss: 0.5057\n",
      "Epoch 14/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 94ms/step - accuracy: 0.9369 - loss: 0.2305 - val_accuracy: 0.8541 - val_loss: 0.5134\n",
      "Epoch 15/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.9420 - loss: 0.2172 - val_accuracy: 0.8513 - val_loss: 0.5253\n",
      "Epoch 16/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 98ms/step - accuracy: 0.9418 - loss: 0.2059 - val_accuracy: 0.8569 - val_loss: 0.5146\n",
      "Epoch 17/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 130ms/step - accuracy: 0.9491 - loss: 0.1859 - val_accuracy: 0.8587 - val_loss: 0.5208\n",
      "Epoch 18/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - accuracy: 0.9501 - loss: 0.1824 - val_accuracy: 0.8494 - val_loss: 0.5287\n",
      "Epoch 19/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 137ms/step - accuracy: 0.9568 - loss: 0.1643 - val_accuracy: 0.8569 - val_loss: 0.5112\n",
      "Epoch 20/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 134ms/step - accuracy: 0.9545 - loss: 0.1602 - val_accuracy: 0.8550 - val_loss: 0.5190\n"
     ]
    }
   ],
   "source": [
    "lstm_model_pretrained.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = lstm_model_pretrained.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a70874da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.79      1.00      0.88        11\n",
      "           2       0.95      0.95      0.95        19\n",
      "           3       0.88      0.88      0.88         8\n",
      "           4       0.81      0.87      0.84        15\n",
      "           5       0.86      0.92      0.89        13\n",
      "           6       0.62      0.68      0.65        19\n",
      "           7       1.00      0.95      0.97        19\n",
      "           8       0.82      0.74      0.78        19\n",
      "           9       0.85      0.58      0.69        19\n",
      "          10       0.67      0.75      0.71         8\n",
      "          11       0.74      0.89      0.81        19\n",
      "          12       0.80      1.00      0.89         8\n",
      "          13       0.89      0.84      0.86        19\n",
      "          14       0.92      0.58      0.71        19\n",
      "          15       0.86      0.95      0.90        19\n",
      "          16       0.95      1.00      0.97        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       1.00      1.00      1.00        19\n",
      "          20       1.00      1.00      1.00        19\n",
      "          21       0.92      1.00      0.96        12\n",
      "          22       1.00      0.95      0.97        19\n",
      "          23       0.95      1.00      0.97        19\n",
      "          24       0.35      0.37      0.36        19\n",
      "          25       1.00      1.00      1.00        19\n",
      "          26       0.94      0.94      0.94        16\n",
      "          27       0.95      0.95      0.95        19\n",
      "          28       0.78      0.74      0.76        19\n",
      "          29       0.73      0.92      0.81        12\n",
      "          30       0.90      0.95      0.92        19\n",
      "          31       0.33      0.67      0.44         3\n",
      "          32       0.83      0.36      0.50        14\n",
      "          33       0.88      0.78      0.82         9\n",
      "          34       0.75      0.86      0.80         7\n",
      "          35       0.72      0.95      0.82        19\n",
      "          36       0.94      0.84      0.89        19\n",
      "          37       0.94      0.89      0.92        19\n",
      "          38       0.85      0.61      0.71        18\n",
      "          39       0.72      0.68      0.70        19\n",
      "          40       1.00      1.00      1.00         7\n",
      "          41       0.80      0.63      0.71        19\n",
      "          42       0.89      0.89      0.89        19\n",
      "          43       1.00      0.63      0.77        19\n",
      "          44       0.48      0.84      0.62        19\n",
      "          45       0.92      0.58      0.71        19\n",
      "          46       0.83      0.79      0.81        19\n",
      "          47       1.00      0.95      0.97        19\n",
      "          48       0.86      0.95      0.90        19\n",
      "          49       0.33      0.42      0.37        19\n",
      "          50       1.00      0.93      0.96        14\n",
      "          51       0.95      0.95      0.95        19\n",
      "          52       0.74      0.74      0.74        19\n",
      "          53       0.94      0.79      0.86        19\n",
      "          54       0.90      0.90      0.90        10\n",
      "          55       0.95      0.95      0.95        19\n",
      "          56       0.78      1.00      0.88        18\n",
      "          57       0.94      0.79      0.86        19\n",
      "          58       0.90      1.00      0.95        19\n",
      "          59       0.78      0.74      0.76        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.95      0.95      0.95        19\n",
      "          62       0.86      0.95      0.90        19\n",
      "          63       0.67      0.74      0.70        19\n",
      "\n",
      "    accuracy                           0.84      1076\n",
      "   macro avg       0.85      0.84      0.84      1076\n",
      "weighted avg       0.86      0.84      0.84      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = lstm_model_pretrained.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdfee9",
   "metadata": {},
   "source": [
    "# 4. embedding từ đâu + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ad048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manh/code/nlp/.venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.2704 - loss: 3.2282 - val_accuracy: 0.5809 - val_loss: 1.9130\n",
      "Epoch 2/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 119ms/step - accuracy: 0.6979 - loss: 1.3560 - val_accuracy: 0.7918 - val_loss: 0.9213\n",
      "Epoch 3/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 113ms/step - accuracy: 0.8405 - loss: 0.7101 - val_accuracy: 0.8401 - val_loss: 0.6986\n",
      "Epoch 4/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 120ms/step - accuracy: 0.9017 - loss: 0.4431 - val_accuracy: 0.8606 - val_loss: 0.5782\n",
      "Epoch 5/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 125ms/step - accuracy: 0.9344 - loss: 0.2975 - val_accuracy: 0.8606 - val_loss: 0.5338\n",
      "Epoch 6/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 124ms/step - accuracy: 0.9539 - loss: 0.2117 - val_accuracy: 0.8690 - val_loss: 0.5349\n",
      "Epoch 7/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 124ms/step - accuracy: 0.9637 - loss: 0.1681 - val_accuracy: 0.8699 - val_loss: 0.5335\n",
      "Epoch 8/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 124ms/step - accuracy: 0.9716 - loss: 0.1260 - val_accuracy: 0.8745 - val_loss: 0.5499\n",
      "Epoch 9/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 129ms/step - accuracy: 0.9779 - loss: 0.1033 - val_accuracy: 0.8773 - val_loss: 0.5045\n",
      "Epoch 10/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 122ms/step - accuracy: 0.9795 - loss: 0.0861 - val_accuracy: 0.8801 - val_loss: 0.5319\n",
      "Epoch 11/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 121ms/step - accuracy: 0.9825 - loss: 0.0747 - val_accuracy: 0.8783 - val_loss: 0.5179\n",
      "Epoch 12/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 121ms/step - accuracy: 0.9878 - loss: 0.0610 - val_accuracy: 0.8597 - val_loss: 0.5623\n",
      "Epoch 13/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 118ms/step - accuracy: 0.9891 - loss: 0.0527 - val_accuracy: 0.8634 - val_loss: 0.5903\n",
      "Epoch 14/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 120ms/step - accuracy: 0.9887 - loss: 0.0500 - val_accuracy: 0.8764 - val_loss: 0.5525\n",
      "Epoch 15/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 121ms/step - accuracy: 0.9910 - loss: 0.0404 - val_accuracy: 0.8773 - val_loss: 0.5799\n",
      "Epoch 16/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 125ms/step - accuracy: 0.9922 - loss: 0.0355 - val_accuracy: 0.8801 - val_loss: 0.5677\n",
      "Epoch 17/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 119ms/step - accuracy: 0.9924 - loss: 0.0332 - val_accuracy: 0.8773 - val_loss: 0.5914\n",
      "Epoch 18/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 121ms/step - accuracy: 0.9935 - loss: 0.0299 - val_accuracy: 0.8727 - val_loss: 0.6020\n",
      "Epoch 19/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 119ms/step - accuracy: 0.9942 - loss: 0.0287 - val_accuracy: 0.8625 - val_loss: 0.6079\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        19\n",
      "           1       0.85      1.00      0.92        11\n",
      "           2       0.84      0.84      0.84        19\n",
      "           3       1.00      0.88      0.93         8\n",
      "           4       1.00      0.87      0.93        15\n",
      "           5       0.93      1.00      0.96        13\n",
      "           6       0.65      0.58      0.61        19\n",
      "           7       0.90      1.00      0.95        19\n",
      "           8       0.60      0.79      0.68        19\n",
      "           9       0.93      0.68      0.79        19\n",
      "          10       0.55      0.75      0.63         8\n",
      "          11       0.81      0.89      0.85        19\n",
      "          12       0.80      1.00      0.89         8\n",
      "          13       0.89      0.84      0.86        19\n",
      "          14       0.65      0.58      0.61        19\n",
      "          15       0.86      0.95      0.90        19\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        19\n",
      "          18       1.00      1.00      1.00        19\n",
      "          19       0.95      1.00      0.97        19\n",
      "          20       0.90      1.00      0.95        19\n",
      "          21       1.00      1.00      1.00        12\n",
      "          22       1.00      1.00      1.00        19\n",
      "          23       0.90      1.00      0.95        19\n",
      "          24       0.29      0.26      0.28        19\n",
      "          25       0.95      1.00      0.97        19\n",
      "          26       1.00      1.00      1.00        16\n",
      "          27       1.00      0.84      0.91        19\n",
      "          28       0.94      0.79      0.86        19\n",
      "          29       0.80      1.00      0.89        12\n",
      "          30       1.00      0.89      0.94        19\n",
      "          31       0.60      1.00      0.75         3\n",
      "          32       1.00      0.79      0.88        14\n",
      "          33       0.78      0.78      0.78         9\n",
      "          34       0.86      0.86      0.86         7\n",
      "          35       0.80      0.84      0.82        19\n",
      "          36       0.85      0.89      0.87        19\n",
      "          37       1.00      0.89      0.94        19\n",
      "          38       0.75      0.67      0.71        18\n",
      "          39       0.88      0.74      0.80        19\n",
      "          40       1.00      0.71      0.83         7\n",
      "          41       0.75      0.63      0.69        19\n",
      "          42       0.82      0.95      0.88        19\n",
      "          43       0.74      0.74      0.74        19\n",
      "          44       0.76      0.68      0.72        19\n",
      "          45       0.95      0.95      0.95        19\n",
      "          46       0.83      0.79      0.81        19\n",
      "          47       1.00      1.00      1.00        19\n",
      "          48       0.86      0.95      0.90        19\n",
      "          49       0.50      0.58      0.54        19\n",
      "          50       0.92      0.86      0.89        14\n",
      "          51       1.00      1.00      1.00        19\n",
      "          52       0.73      0.84      0.78        19\n",
      "          53       1.00      0.74      0.85        19\n",
      "          54       0.80      0.80      0.80        10\n",
      "          55       0.95      0.95      0.95        19\n",
      "          56       0.83      0.83      0.83        18\n",
      "          57       1.00      0.84      0.91        19\n",
      "          58       0.90      1.00      0.95        19\n",
      "          59       0.62      0.79      0.70        19\n",
      "          60       1.00      1.00      1.00        18\n",
      "          61       0.93      0.74      0.82        19\n",
      "          62       0.95      1.00      0.97        19\n",
      "          63       0.57      0.68      0.62        19\n",
      "\n",
      "    accuracy                           0.85      1076\n",
      "   macro avg       0.86      0.86      0.85      1076\n",
      "weighted avg       0.86      0.85      0.85      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_scratch = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=100, # Chọn một chiều embedding, ví dụ 100\n",
    "        input_length=max_len,\n",
    "        mask_zero=True,\n",
    "        # Không có weights, trainable=True (mặc định)\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 2. Compile, huấn luyện và đánh giá mô hình\n",
    "lstm_model_scratch.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = lstm_model_scratch.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdbbf9",
   "metadata": {},
   "source": [
    "loss trên tập test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d06c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "Log Loss on test set: 0.5858633518218994\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = lstm_model_scratch.predict(X_test_pad)\n",
    "log_loss = -np.mean(np.log(y_pred_proba[np.arange(len(y_test)), y_test]))\n",
    "print(f\"Log Loss on test set: {log_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
