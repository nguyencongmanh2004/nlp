{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:28:06.277309Z",
     "start_time": "2025-11-23T11:28:04.439059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert/distilroberta-base\"\n",
    "\n",
    "# Lấy tokenizer để biết token mask đúng\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "mask_token = tokenizer.mask_token  # sẽ là \"<mask>\"\n",
    "\n",
    "mask_filler = pipeline('fill-mask', model=model_name, tokenizer=tokenizer, device=0)\n",
    "\n",
    "input_sentence = f\"ha noi is {mask_token} of vietnam\"\n",
    "\n",
    "predictions = mask_filler(input_sentence , top_k=5)\n",
    "\n",
    "print(f\"câu gốc : {input_sentence}\")\n",
    "for pred in predictions:\n",
    "    print(f\"predicted : {pred['token_str']} độ tin cậy {pred['score']:.4f}\")\n",
    "    print(f\"-> full sentence: {pred['sequence']}\")\n"
   ],
   "id": "933f0f236a369c05",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "câu gốc : ha noi is <mask> of vietnam\n",
      "predicted :  king độ tin cậy 0.2076\n",
      "-> full sentence: ha noi is king of vietnam\n",
      "predicted :  lord độ tin cậy 0.0848\n",
      "-> full sentence: ha noi is lord of vietnam\n",
      "predicted :  part độ tin cậy 0.0474\n",
      "-> full sentence: ha noi is part of vietnam\n",
      "predicted :  afraid độ tin cậy 0.0324\n",
      "-> full sentence: ha noi is afraid of vietnam\n",
      "predicted :  worthy độ tin cậy 0.0290\n",
      "-> full sentence: ha noi is worthy of vietnam\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Bai2",
   "id": "e4ae2d6ec4e92544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation')\n",
    "\n"
   ],
   "id": "9298923138b803e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T06:28:18.226325Z",
     "start_time": "2025-11-24T06:28:04.530092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"the best thing about learning NLP is\"\n",
    "\n",
    "generated_texts = generator(prompt , max_length=50 , num_return_sequences = 1)\n",
    "\n",
    "print(f\"Câu mồi: '{prompt}'\")\n",
    "for text in generated_texts:\n",
    "    print(\"Văn bản được sinh ra:\")\n",
    "    print(text['generated_text'])"
   ],
   "id": "668eec786defec5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu mồi: 'the best thing about learning NLP is'\n",
      "Văn bản được sinh ra:\n",
      "the best thing about learning NLP is that you have a lot of freedom to do what you want with your time. It makes it easy to do things that you're not allowed to do.\"\n",
      "\n",
      "He added that by having a \"comfortable space\" in the classroom, students can become better communicators.\n",
      "\n",
      "\"It's a positive thing for all of us because it's very rewarding,\" he said. \"We can also say, 'OK, you're learning to make it better.' You have to be a better communicator, as opposed to the one you are.\"\n",
      "\n",
      "The new training is based on a study by the University of California, Berkeley where the students were asked to perform a five-minute task \"notifying listeners of how much they really care about the outcome.\" During that time, the participants were asked to complete a series of questionnaires, each of which had a total of 10 questions.\n",
      "\n",
      "The researchers used a computer program called \"Brainstormer,\" which they developed to measure brain activity during the task.\n",
      "\n",
      "The researchers found that when participants were given a question as simple as \"The number of times you've seen a person you know or know that you know\" and then asked \"How much of that is based on your level of interest in that person?\"\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# bai3",
   "id": "bf91432192f8d07a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T06:50:04.420802Z",
     "start_time": "2025-11-24T06:49:16.519079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer , AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# cau dau vao\n",
    "sentences = ['this is sample sentence']\n",
    "\n",
    "inputs = tokenizer(sentences , padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "\n",
    "attention_mask =inputs['attention_mask']\n",
    "mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "\n",
    "sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)\n",
    "sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "sentence_embedding = sum_embeddings / sum_mask\n",
    "# 6. In kết quả\n",
    "print(\"Vector biểu diễn của câu:\")\n",
    "print(sentence_embedding)\n",
    "print(\"\\nKích thước của vector:\", sentence_embedding.shape)\n"
   ],
   "id": "582df9388ee3ec6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd95c3811af24bb98f0ec39028ce13b4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efd1b77056c546fcb527327b34b447b8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd3458a984ef444c84c9807b1aebdd3b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e2f8759b81b4a669cc34f37b27baa24"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95c3a50a6acf4986a9c4061d04b89c75"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector biểu diễn của câu:\n",
      "tensor([[-1.7937e-01, -2.7563e-01, -8.6277e-02, -4.0896e-01,  1.4436e-02,\n",
      "         -8.9069e-02,  5.5756e-01,  2.1660e-01, -1.5305e-02, -3.7305e-03,\n",
      "         -2.6640e-01, -2.4981e-01, -4.3882e-02,  2.8130e-01,  9.5678e-02,\n",
      "          2.1535e-01,  1.7708e-01,  5.5628e-02,  1.6676e-01,  3.7188e-02,\n",
      "          5.1087e-01,  3.1202e-01, -3.8073e-01, -8.5085e-02,  8.8970e-01,\n",
      "         -2.1824e-01, -1.5890e-01, -6.6209e-02, -8.3649e-01, -4.1072e-02,\n",
      "          1.3197e-01,  2.7028e-01, -6.6788e-02,  6.8739e-02, -4.2942e-01,\n",
      "         -5.7768e-01,  2.4568e-02, -1.0478e-01, -2.0277e-01,  8.0705e-02,\n",
      "         -4.2998e-01, -2.6549e-01,  2.7291e-01,  6.6352e-02, -4.2351e-02,\n",
      "         -1.0494e-01, -6.2446e-02, -2.4555e-01, -4.3781e-01, -5.1084e-02,\n",
      "         -6.7253e-01,  1.3201e-01,  3.6432e-01,  2.8997e-01, -4.3930e-01,\n",
      "          4.8714e-01,  2.4102e-01, -5.6733e-01,  9.7037e-03, -3.1274e-01,\n",
      "          5.1978e-01,  1.5108e-01,  8.4002e-02, -3.7446e-01,  4.3011e-01,\n",
      "          1.3118e-01,  2.3095e-01,  2.8477e-01, -1.1603e+00,  2.6631e-01,\n",
      "         -4.0075e-01, -3.4387e-01,  2.3534e-01,  1.1234e-01, -6.1202e-02,\n",
      "          7.5897e-02, -3.5370e-01,  3.3940e-01, -3.1689e-01, -6.9510e-01,\n",
      "         -5.5139e-02,  4.0813e-01, -1.1497e-01,  1.3027e-01, -1.4007e-01,\n",
      "         -1.9382e-01, -1.3679e-01, -1.8861e-01, -6.7172e-01,  6.1729e-01,\n",
      "          2.2561e-01, -1.2825e-01, -1.2223e-01, -1.3552e-01,  5.3760e-01,\n",
      "         -1.6781e-01, -9.8125e-02,  1.6154e-01, -8.6003e-02,  6.3363e-04,\n",
      "         -2.9458e-01, -9.5054e-01,  5.3827e-01,  2.6524e-01, -1.4397e-01,\n",
      "         -1.1455e-01,  1.4409e-02,  4.3474e-01,  5.6047e-02, -2.1021e-01,\n",
      "          1.8231e-01, -1.3822e-01,  4.4483e-02, -2.3642e-01, -3.3180e-01,\n",
      "          2.7507e-01,  8.0110e-02,  3.1122e-01, -1.1373e-01, -2.1918e-01,\n",
      "         -3.9635e-01,  5.7396e-02,  4.0773e-01,  7.4125e-01, -7.7471e-02,\n",
      "          3.2545e-01,  1.2863e-02,  2.6160e-01,  4.2767e-01, -2.1606e-01,\n",
      "          1.4221e-01,  5.5515e-01,  4.9815e-01,  5.5226e-02, -1.1038e-01,\n",
      "         -3.5264e-01,  1.6170e-02, -2.9844e-01, -6.3619e-01,  4.7598e-02,\n",
      "          1.7865e-01,  3.6829e-01,  2.9797e-01, -4.1230e-01,  4.0036e-02,\n",
      "         -3.5166e-02, -4.7066e-01, -1.4229e-01,  2.2073e-01,  2.5446e-01,\n",
      "          1.6165e-01,  4.1907e-02, -5.3388e-01, -1.6938e-01, -2.2189e-01,\n",
      "          2.7209e-01,  6.8142e-02,  3.8168e-01, -1.1975e-01,  1.3612e-01,\n",
      "          7.1577e-01,  4.2383e-01,  1.1050e-01, -3.7549e-02,  8.3439e-02,\n",
      "         -1.3079e-01, -2.1111e-01,  3.9631e-01, -3.9711e-02, -1.8385e-01,\n",
      "         -2.2774e-01, -3.9997e-01,  7.0773e-01, -5.3726e-02, -2.8531e-01,\n",
      "          2.8412e-01,  4.3074e-01, -1.5999e-01,  1.6842e-01, -4.7289e-01,\n",
      "         -1.6440e+00,  4.9877e-01, -1.2486e-01, -6.5335e-01,  1.5996e-01,\n",
      "         -1.9280e-01,  5.7168e-01, -1.3021e-01,  1.6681e-01, -1.5182e-01,\n",
      "         -1.4355e-01, -2.0142e-01, -3.5772e-01, -3.2936e-01, -2.4674e-02,\n",
      "          6.3217e-02, -1.5250e-01, -4.1186e-01,  1.0854e-01,  6.7519e-03,\n",
      "          1.4996e-01,  9.1974e-02,  2.3800e-01,  2.3901e-02, -2.3044e-01,\n",
      "          2.4947e-01,  8.8090e-02,  9.1120e-02,  1.1955e-01,  4.4925e-01,\n",
      "         -3.7261e-01,  1.1288e+00,  3.4937e-01, -2.9512e-01,  4.6492e-01,\n",
      "          4.6948e-02,  1.0568e-02, -3.1727e-01,  9.4964e-02, -4.1695e-02,\n",
      "          2.3376e-02, -2.0579e-01, -2.2305e-01,  2.8579e-01, -5.3211e-01,\n",
      "          3.1805e-01,  1.1061e-01,  2.4561e-01,  6.1341e-01, -1.0434e-01,\n",
      "         -3.4295e-02, -2.6624e-01,  2.2949e-01,  2.2721e-01, -2.4777e-01,\n",
      "          3.6454e-01,  8.9322e-02,  4.7290e-01, -3.1061e-01, -4.1709e-02,\n",
      "          2.7619e-02,  5.5667e-01,  4.1637e-01, -1.4507e-01, -2.8515e-01,\n",
      "         -5.1692e-01,  1.4505e-02, -1.3007e-01,  1.0050e-02, -4.4083e-01,\n",
      "         -3.2728e-01, -4.1137e-01, -2.4449e-01, -1.4052e-01, -3.1384e-01,\n",
      "          2.3142e-01, -1.8151e-03,  6.3930e-02,  4.6301e-01,  2.9217e-01,\n",
      "         -1.0067e-01,  1.8415e-01,  1.2926e-01,  3.3473e-01, -5.3850e-01,\n",
      "         -3.8401e-02, -5.5113e-02,  2.5947e-01,  6.3715e-01,  2.2817e-01,\n",
      "         -5.0159e-01, -6.2486e-01, -2.5548e-01, -3.1124e-02, -1.6652e-01,\n",
      "         -1.3987e-01,  2.8236e-01,  8.5927e-02, -1.2463e-01,  3.7035e-02,\n",
      "          8.0492e-02,  4.8757e-01,  1.4306e-01,  4.6816e-02,  1.9043e-01,\n",
      "         -6.3549e-01,  1.3765e-01, -6.3374e-02,  4.0694e-01, -1.5421e-01,\n",
      "         -5.7014e-01,  9.1193e-02, -2.2007e-01, -1.7442e-01,  4.5110e-01,\n",
      "          2.1983e-01,  3.1738e-01,  1.1973e-01, -2.2432e-01, -5.0625e-01,\n",
      "         -2.4712e-01, -3.9669e-01, -3.0431e-01, -3.7039e-02, -7.2790e-01,\n",
      "          4.2334e-01,  2.0851e-01, -2.3279e-01, -3.3658e+00, -2.0901e-03,\n",
      "         -2.0936e-01, -2.8551e-01,  1.0517e-01, -3.2657e-01, -2.5712e-02,\n",
      "         -3.3920e-01, -4.6398e-01,  1.8565e-01, -4.5880e-01, -7.4119e-01,\n",
      "          2.4855e-01,  6.7617e-01,  3.4601e-01,  2.6785e-02, -2.5019e-01,\n",
      "          1.2249e-01, -3.1726e-03,  6.0129e-01,  9.8426e-02, -8.4867e-02,\n",
      "          9.9062e-02, -4.7243e-01,  2.8903e-01, -2.7566e-02, -4.3792e-01,\n",
      "          3.6832e-01, -4.6170e-01, -6.5764e-01, -7.6223e-02, -9.1841e-02,\n",
      "          6.0551e-02, -2.5373e-01, -3.1427e-01,  1.0176e-01,  2.4979e-01,\n",
      "         -3.7788e-02,  6.7533e-01, -2.0154e-01, -3.6930e-01,  2.7857e-01,\n",
      "          2.3382e-01, -1.1213e-01,  4.5311e-01, -3.1630e-01, -3.2199e-01,\n",
      "         -4.5067e-01,  2.6354e-01,  5.1059e-01, -3.8375e-01, -2.4631e-01,\n",
      "          4.0695e-01,  1.8607e-01,  1.4078e-01, -1.0317e-01,  1.6853e-01,\n",
      "          3.6478e-01, -8.8262e-02, -2.9339e-01,  5.1314e-01, -3.5669e-01,\n",
      "         -4.6623e-02, -2.1419e-01,  2.9194e-01, -2.6726e-01, -3.5211e-01,\n",
      "         -6.5383e-02, -1.9980e-01,  5.0601e-01, -3.5320e-01, -3.4864e-01,\n",
      "         -2.4168e-01, -9.7112e-01, -2.7493e-01, -5.1988e-02,  2.6977e-01,\n",
      "         -2.5826e-01,  2.7793e-01, -3.3135e-01, -3.2258e-01, -5.1246e-01,\n",
      "          3.4170e-02,  3.5789e-02,  1.8060e-01,  1.2167e-01, -3.5011e-02,\n",
      "         -5.2900e-01, -2.5907e-01, -3.9818e-01, -2.2870e-01, -1.3123e-02,\n",
      "          5.7168e-02,  7.0207e-03, -5.8969e-02,  4.8810e-01,  6.9074e-01,\n",
      "         -6.8611e-01,  4.0742e-01, -3.0472e-01,  1.9939e-01, -4.0450e-01,\n",
      "          3.3978e-01, -2.1717e-01,  1.1733e-01,  1.5134e-02, -9.7303e-01,\n",
      "          4.9577e-01,  2.7363e-01,  5.0007e-02,  1.7924e-01, -1.9752e-01,\n",
      "          7.5483e-02, -1.0031e-01, -7.8599e-02,  7.9456e-02, -4.6190e-01,\n",
      "          2.7586e-01,  5.2013e-01,  1.7946e-01,  1.5010e-01,  1.7820e-01,\n",
      "         -6.2798e-01, -3.5542e-01, -6.6902e-01, -1.4548e-01, -2.2344e-01,\n",
      "          1.5559e-01, -5.7955e-01, -3.9708e-01, -4.7396e-01,  5.5147e-02,\n",
      "         -8.3038e-02, -6.7598e-02,  3.8519e-01, -5.2256e-01,  2.1441e-01,\n",
      "          8.5865e-01,  7.0308e-01, -3.1005e-01,  4.2257e-01,  1.4400e-01,\n",
      "         -2.6076e-01, -7.1385e-02, -4.8318e-01,  7.5181e-01,  9.6515e-03,\n",
      "         -2.8810e-01,  1.5577e-02,  6.6316e-02, -4.5476e-02, -2.9822e-01,\n",
      "          1.6532e-01, -3.0275e-01,  8.0134e-02, -5.0772e-01,  2.2358e-01,\n",
      "         -7.8458e-03, -3.6267e-01, -1.8085e-01,  1.7085e-01,  9.1982e-02,\n",
      "          6.2658e-02, -1.8425e-01, -8.0802e-02,  6.9487e-02,  2.1440e-01,\n",
      "          9.2029e-02, -2.9534e-01,  4.7599e-01, -1.7686e-01, -6.2924e-02,\n",
      "          3.4153e-01, -1.9409e-01,  2.5156e-01,  3.3653e-01,  4.6455e-01,\n",
      "         -2.3428e-01,  1.3910e-01,  8.6793e-01,  1.5897e-01,  1.2285e-01,\n",
      "          1.0983e-01,  3.7403e-01,  4.1837e-01,  7.2405e-01, -2.1483e-01,\n",
      "          3.4913e-01,  4.5792e-01,  3.5264e-02, -9.6888e-02, -1.4911e-01,\n",
      "         -3.6331e-01, -3.5102e-01, -4.4764e-01, -3.3729e-01,  1.5017e-01,\n",
      "          1.6210e-01,  1.1494e-01,  1.7480e-01,  5.4462e-01,  8.6812e-02,\n",
      "         -2.9348e-01, -3.0379e-01,  1.3573e-01,  5.8814e-03,  4.7141e-02,\n",
      "          1.8374e-01,  1.8042e-01, -5.7233e-03, -1.4594e-01, -3.7718e-01,\n",
      "         -4.0278e-01, -7.3609e-01, -8.5475e-02, -1.8533e-02,  2.4212e-01,\n",
      "          3.5151e-01,  2.4702e-02, -4.5838e-01, -1.1761e-01, -2.1168e-01,\n",
      "          1.4208e-01,  1.1459e-01,  3.8206e-02, -2.9663e-01, -2.5090e-01,\n",
      "         -6.3779e-01, -2.3379e-01,  1.9125e-01,  2.5128e-01, -2.5258e-01,\n",
      "          7.9057e-02,  2.7623e-02, -2.8144e-03, -6.7396e-01, -6.0049e-01,\n",
      "         -4.2402e-03,  3.5577e-02, -6.0715e-01,  4.2057e-02, -7.7155e-02,\n",
      "         -6.5043e-02, -6.4629e-01, -4.8685e-02, -1.8646e-01,  2.3287e-01,\n",
      "          5.8494e-01,  1.9021e-01,  5.4272e-01, -2.6992e-01,  4.6577e-01,\n",
      "         -2.9512e-01, -4.7404e-02,  4.0561e-01, -4.5723e-01, -2.7914e-01,\n",
      "          2.7536e-01, -5.1502e-01,  2.5509e-01,  3.7572e-01, -1.5405e-01,\n",
      "         -8.9088e-02,  6.7720e-01,  3.7265e-01,  5.3079e-01,  3.2711e-02,\n",
      "          1.2969e-01, -4.1340e-02,  3.0605e-01, -3.0130e-01,  1.4408e-01,\n",
      "         -9.0944e-02,  3.6430e-01,  1.5900e-01, -3.0834e-01,  3.4761e-04,\n",
      "         -2.1339e-01,  5.3259e-02,  1.3309e-01,  1.5753e-01,  1.5551e-01,\n",
      "         -5.7458e-01,  6.7703e-02,  6.0665e-01,  2.0056e-01, -4.1251e-01,\n",
      "          1.1026e-01, -1.3684e-01, -2.7251e-01,  9.8628e-03,  1.6892e-01,\n",
      "         -2.0217e-01, -9.5200e-02, -2.0457e-01,  3.9909e-03,  2.6949e-01,\n",
      "          4.0876e-01, -1.5867e-01, -1.8418e-01,  5.6931e-02,  1.9087e-01,\n",
      "          1.9102e-01,  1.1932e-01, -5.6191e-01,  1.0496e-01,  4.1754e-01,\n",
      "         -2.6455e-01,  2.5433e-01, -6.6327e-02,  1.3613e-01, -4.3683e-02,\n",
      "          5.4322e-01,  4.0635e-01, -3.5470e-01, -3.5382e-01,  7.6526e-02,\n",
      "         -4.4692e-01,  1.3372e-01,  2.4645e-01, -2.7704e-02, -1.4185e-01,\n",
      "          4.7290e-01,  1.5678e-01, -3.6580e-01,  5.9626e-01, -3.3576e-01,\n",
      "         -4.0987e-02, -2.3285e-02,  1.9942e-01,  3.9517e-01,  3.8513e-01,\n",
      "         -3.4144e-01,  8.9124e-01, -6.6145e-01, -1.9149e-01,  1.0522e-01,\n",
      "          1.0921e-01,  4.2842e-01, -3.7369e-01,  3.7141e-01,  4.3241e-01,\n",
      "          5.1724e-02,  4.0903e-01, -2.4209e-01, -4.9104e-01, -1.4427e-01,\n",
      "         -6.6306e-02,  2.6317e-01,  6.6092e-01,  3.9597e-01,  2.2543e-01,\n",
      "          2.6837e-01,  1.0399e-01,  1.0101e-01,  8.8484e-02,  3.3346e-01,\n",
      "          2.4241e-01,  2.1561e-01, -3.4016e-01,  2.3544e-01, -6.7538e-02,\n",
      "         -1.3714e-02, -2.7356e-01, -1.2570e-01,  1.1632e-01,  2.2604e-01,\n",
      "          1.8690e-01, -2.5867e-01,  1.5577e-01,  5.2435e-02,  6.8705e-02,\n",
      "         -1.4503e-01, -2.9544e-01, -1.9384e-01,  4.7080e-01, -2.6447e-01,\n",
      "          1.0728e-01, -5.4451e-01,  3.8601e-01,  2.9469e-01,  1.4595e-01,\n",
      "         -3.4612e-01, -2.9482e-01, -6.2864e-02, -3.4936e-01, -1.3939e-02,\n",
      "         -5.2471e-02, -7.7156e-03, -3.4659e-02, -3.6999e-01, -4.1861e-01,\n",
      "          1.7439e-01, -3.2487e-01,  4.5600e-01,  4.9216e-03,  3.9724e-02,\n",
      "          3.9968e-01,  5.3316e-01, -1.7562e-01,  5.3303e-01, -3.6556e-01,\n",
      "         -1.2294e-01,  1.1699e-01,  2.4621e-01,  5.2363e-02, -3.2183e-01,\n",
      "          3.1122e-01, -3.5652e-02, -1.9420e-01,  3.5351e-01,  3.3164e-01,\n",
      "         -8.2571e-01,  2.3275e-01, -2.0233e-01, -1.8040e-01, -2.3337e-01,\n",
      "         -1.3741e-01,  1.8999e-01,  4.0569e-02, -4.9495e-01, -5.1195e-01,\n",
      "         -4.9951e-02,  4.9269e-01, -1.8484e-01, -1.7207e-01, -1.0320e-01,\n",
      "          2.7160e-01, -3.0508e-01,  7.0123e-02,  1.4604e-01,  1.1428e-01,\n",
      "          3.0592e-01,  2.8664e-01,  3.4644e-01, -4.7707e-01,  1.1769e-01,\n",
      "         -1.0237e-01,  4.3715e-02, -2.4246e-02, -6.3558e-01,  5.2625e-01,\n",
      "         -3.7093e-02,  3.2355e-01, -1.2333e+00,  2.6606e-01,  4.3330e-01,\n",
      "         -1.9334e-01, -1.3335e-01, -2.6915e-01,  4.1521e-01, -1.0877e-01,\n",
      "         -1.4062e-01, -4.4069e-01, -3.8469e-01,  1.0351e-01,  5.6044e-01,\n",
      "         -9.2087e-02,  9.7461e-02,  3.2495e-01]])\n",
      "\n",
      "Kích thước của vector: torch.Size([1, 768])\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
